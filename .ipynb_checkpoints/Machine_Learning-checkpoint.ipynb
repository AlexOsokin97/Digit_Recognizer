{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./Engineered_csv/Engineered_X_train.csv')\n",
    "X_test = pd.read_csv('./Engineered_csv/Engineered_X_test.csv')\n",
    "y_train = pd.read_csv('./Engineered_csv/X_train_label.csv')\n",
    "y_test = pd.read_csv('./Engineered_csv/X_test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 9)\n",
      "(4200, 9)\n",
      "(37800, 1)\n",
      "(4200, 1)\n"
     ]
    }
   ],
   "source": [
    "sets = [X_train, X_test, y_train, y_test]\n",
    "\n",
    "for x in range(len(sets)):\n",
    "    print(sets[x].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for machine learning algorithm's useage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, training_features, training_labels,metric, kfolds):\n",
    "    '''\n",
    "    A function that applies cross_validation on given machine learning algorithm, data and number of data splits\n",
    "    \n",
    "    input:\n",
    "            model (sklearn machine learning algorithm api): LogisticRegression, XGBoost, etc..\n",
    "            training_features (DataFrame): (X_train)\n",
    "            training_labels (DataFrame): (y_train)\n",
    "            metric (String, sklearn scoring metrics api): \n",
    "            kfolds (int): number of splits to perform on the datasets\n",
    "    \n",
    "    output:\n",
    "            scores (list): a list with scoring values for each K split\n",
    "            average_score (float): the mean of scores\n",
    "            \n",
    "    '''\n",
    "    scores = cross_val_score(estimator=model, X=training_features.values, y=training_labels.values.ravel(), scoring=metric, cv=kfolds)\n",
    "    average_score = np.mean(scores)\n",
    "    return scores, average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning(model, training_features, training_labels,metric, hyper_params, cv):\n",
    "    '''\n",
    "    A function that applies GridSearch (hyper parameter tuning) for a given machine learning algorithm.\n",
    "    \n",
    "    *In order to get the best of this function it is recommended that you'll use it on algorithms with many hyper parameters*\n",
    "    \n",
    "    input:\n",
    "            model (sklearn machine learning algorithm api): LogisticRegression, XGBoost, etc..\n",
    "            training_features (DataFrame): (X_train)\n",
    "            training_labels (DataFrame): (y_train)\n",
    "            metric (String, sklearn scoring metrics api): \n",
    "            hyper_params (list): A list which contains a dictionary with it's keys as names of a model's hyper parameters and \n",
    "                                 values to test on\n",
    "            cv (int): cross validation splitting strategy (3-fold, 5-fold). *for faster performance choose 3 fold cv*\n",
    "    \n",
    "    output: \n",
    "            best_find (machine learning model): returns the given machine learning algorithm with the best hyper parameters\n",
    "            best_score (float): returns the best score achieved by the model with the best hyper parameters\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid=hyper_params, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    grid_search.fit(training_features.values, training_labels.values.ravel())\n",
    "    best_find = grid_search.best_estimator_\n",
    "    best_score = grid_search.best_score_\n",
    "    return best_find, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(trained_model, testing_features, testing_labels, metrics = []):\n",
    "    '''\n",
    "    A functions that applies multiple scoring metrics given by the user on the testing set\n",
    "    \n",
    "    input:\n",
    "            trained_model (sklearn machine learning algorithm api): An already trained machine learning algorithm\n",
    "            testing_features (DataFrame): (X_test) \n",
    "            testing_label (DataFrame): (y_test)\n",
    "            metrics (list of sklearn metric api): a list which contains the desired scoring metrics\n",
    "    \n",
    "    output:\n",
    "            scores (dictionary): a dictionary which contains the scoring method as a key and the score as value\n",
    "            \n",
    "    '''\n",
    "    scores = {}\n",
    "    num_metrics = 1\n",
    "    predictions = trained_model.predict(testing_features.values)\n",
    "    for metric in metrics:\n",
    "        \n",
    "        if str(metric) == str(f1_score):\n",
    "            score = f1_score(testing_labels.values.ravel(), predictions, average='micro')\n",
    "            scores[num_metrics] = score\n",
    "            num_metrics += 1\n",
    "        else:\n",
    "            score = metric(testing_labels.values.ravel(), predictions)\n",
    "            scores[num_metrics] = score\n",
    "            num_metrics += 1\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.8989418 , 0.89550265, 0.89338624, 0.9031746 , 0.90291005,\n",
       "        0.89761905, 0.89867725, 0.9021164 , 0.8978836 , 0.9005291 ]),\n",
       " 0.899074074074074)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(lr, X_train, y_train, 'accuracy', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = [{'solver':('newton-cg', 'lbfgs', 'sag'), 'tol': (0.1, 0.01, 0.0005, 0.0001)}]\n",
    "lr_best_estimator, lr_best_score = hyper_tuning(lr, X_train, y_train, 'accuracy', lr_params, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=1, solver='newton-cg', tol=0.1, verbose=0,\n",
      "                   warm_start=False)\n",
      "the score of the best estimator:  0.8888359788359788\n"
     ]
    }
   ],
   "source": [
    "print('best estimator: ' , lr_best_estimator)\n",
    "print('the score of the best estimator: ', lr_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores = model_performance(lr_best_estimator, X_test, y_test, [confusion_matrix, accuracy_score, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[382   0   6   0   0   0   2   0  18   0]\n",
      " [  0 460   0   0   7   0   1   3   0   0]\n",
      " [  7   0 374   0   0   0   9   0  20  10]\n",
      " [  1   3   5 430   0  33   7   3   4  20]\n",
      " [  0   2   0   1 377   0   5   9   0   3]\n",
      " [  0   5   5  26   1 265  22   0   0  15]\n",
      " [  2   2  16   3   0  18 360   1   0   0]\n",
      " [  0  12   0   1  17   8   1 395   0   4]\n",
      " [  2   0  22   0   0   1   1   0 371   6]\n",
      " [  1   1   4  15   3  11   2  20   0 359]]\n",
      "Accuracy:  0.8983333333333333\n",
      "F1-Score:  0.8983333333333333\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', lr_scores[1])\n",
    "print('Accuracy: ', lr_scores[2])\n",
    "print('F1-Score: ', lr_scores[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.87380952, 0.87671958, 0.86957672, 0.87354497, 0.87724868,\n",
       "        0.87936508, 0.87962963, 0.87460317, 0.87513228, 0.87592593]),\n",
       " 0.8755555555555556)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "applying cross validation with 10 fold split\n",
    "'''\n",
    "cross_validation(kn, X_train, y_train, 'accuracy', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "applying a hyper parameter tuning\n",
    "'''\n",
    "lr_params = [{'weights':('uniform', 'distance'), 'leaf_size':(100,300,500)}]\n",
    "kn_best_estimator, kn_best_score = hyper_tuning(kn, X_train, y_train, 'accuracy', lr_params, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator:  KNeighborsClassifier(algorithm='auto', leaf_size=100, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "                     weights='distance')\n",
      "the score of the best estimator:  0.8719576719576719\n"
     ]
    }
   ],
   "source": [
    "print('best estimator: ' , kn_best_estimator)\n",
    "print('the score of the best estimator: ', kn_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_scores = model_performance(kn_best_estimator, X_test, y_test, [confusion_matrix, accuracy_score, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[381   0   4   1   1   7   7   0   7   0]\n",
      " [  0 465   2   1   0   0   2   1   0   0]\n",
      " [  3   0 382   6   3   2  10   6   8   0]\n",
      " [  2   6   8 367   2  23   1   5  80  12]\n",
      " [  0   0   3   0 310   3   5   3   4  69]\n",
      " [  7   0   1  13   7 290   8   2   9   2]\n",
      " [ 10   1   3   0   1   4 380   0   1   2]\n",
      " [  0   6   3   1   4   3   0 396   6  19]\n",
      " [  2   1   8  20   3   7   3   3 354   2]\n",
      " [  3   1   2  10  44   4   4  14   6 328]]\n",
      "Accuracy:  0.8697619047619047\n",
      "F1-Score:  0.8697619047619047\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', kn_scores[1])\n",
    "print('Accuracy: ', kn_scores[2])\n",
    "print('F1-Score: ', kn_scores[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
